{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 需求描述\n",
    "在游戏《幸福工厂》的生产体系中，配方是如$\\sum_{i=1}^{n1} a_i \\cdot x_i = \\sum_{i=1}^{n1} b_i \\cdot y_i$形式的公式，其中$x_i$是输入的原料，$a_i$是单位时间对应原料的消耗量，$y_i$是输出的产物，$b_i$是单位时间对应产物的产出量，一个配方的产出可能是另一个配方的输入，如此构成了生产链路，而链路交叉形成生产网络。\n",
    "对于网络中的产物，可能存在多种配方，不同的配方有不同的原料消耗和生产效率，而基础原料的产量是有上限的，且丰度不同，于是便有了生产网络优化的需求。\n",
    "对于配方生产网络，有m个item、n个formula两种类型节点，同种节点不互相连接。设节点的权重为$\\alpha$和$\\beta$，代表物资和配方的单位数量，边的权重为$W_{m\\times n}$（代表每种配方每单位消耗产出物资数量）。item中有一些特殊的节点为源节点$s=\\alpha_{m\\times 1} \\odot Ms_{m \\times 1}$，其中$Ms_{m \\times 1}$为标示源节点的掩码向量。源节点的需求不应该由formula产出，但是要累计计算资源需求。现需要对一些目标物资的生产路线建模，优化源节点的物资需求。\n",
    "### 思路1 产出逆推需求\n",
    "#### 推导过程\n",
    "可以设想一种传播途径，从某些item节点开始，初始化权重为向量$\\alpha^{pre}_{m\\times 1}$，其中大于0的值表示需求，那么对于小于0表示已经提供的物资。对于权重为$\\alpha_a>0$的节点$item_a$，需要通过生产公式消耗原料来满足其需求，假设其连接n个formula节点，权重为向量$w_{a|n}$，由于每个item可以由不同的formula输出，所以配置可训练向量$a_{a|n}$映射到概率向量$b_{a|n}=softmax(a_{a|n})$来表示每个item的产出需求由不同的formula输出提供的比例，满足$b_{ak}\\cdot \\alpha_a=ReLU(w_{ak})\\cdot \\beta_k$，即$\\beta_k=\\alpha_{ak} \\cdot \\frac{b_{ak}}{w_{ak}},k\\in [1,n]$，同时由于每个formula有多个item产出，formula的实际需求权重应该由产出item中对formula需求最高的项决定，设$B_{m,n}=[b_1,b_2,...,b_m]$，有$\\beta_k=max(\\alpha \\odot \\frac{B_{:,k}}{W_{:,k}})$\n",
    "\n",
    "那么推广到向量$\\beta$，有\n",
    "$$\\begin{aligned}\n",
    "&\\alpha^{pre}_{m\\times 1} \\in R^{m\\times 1} \\quad &(当前的物资需求供应量)\\\\\n",
    "&W_{m\\times n} \\in R^{m\\times n} \\quad &(生产权重矩阵)\\\\\n",
    "&Wb_{m\\times n}= \\frac{1}{W_{m\\times n}}\\quad &(倒数生产权重矩阵，用于通过物资计算配方需求)\\\\\n",
    "&A_{m\\times n}\\in R^{m\\times n} \\quad &(配方的分配权重矩阵，被训练参数)\\\\\n",
    "&P_{m\\times n}=softmax(A_{m\\times n}, dim=1)\\quad &(配方的分配概率矩阵)\\\\\n",
    "&X_{m\\times n}=ReLU(\\alpha^{pre}_{m\\times 1}) \\odot P_{m\\times n} \\odot Wb_{m\\times n}\\quad &(物资对配方的需求强度矩阵)\\\\\n",
    "&\\beta_{n\\times 1}= maxcol(X) \\quad &(配方的需求矩阵)\\\\\n",
    "\\end{aligned}$$\n",
    "\n",
    "但是会有一个问题，即$W_{m\\times n}$的元素可能小于等于0，表示对应物资不是由对应配方生产，对应元素是无效的，不应该纳入计算，且要防止除0问题，所以应该引入掩码和epsilon，即\n",
    "$$\\begin{aligned}\n",
    "&M_{m\\times n} = \\mathbb{I}(W_{m\\times n}>0) \\in \\{0,1\\}^{m\\times n}\\\\\n",
    "&Mp_{m\\times n}=(1−M_{m\\times n})\\odot (-epsilon)\\\\\n",
    "&Wb_{m\\times n}= \\frac{1}{W_{m\\times n} + epsilon \\odot \\mathbb{I}(W_{m\\times n}=0)}\\\\\n",
    "&P_{m\\times n}=softmax(A_{m\\times n}+Mp_{m\\times n}, dim=1) \\odot M_{m\\times n}\\\\\n",
    "\\end{aligned}$$\n",
    "在实际运算中为了防止溢出，这里使用$-epsilon$代替$-\\inf$，epsilon取一个极小数，比如1e-8。\n",
    "\n",
    "以上网络进一步传播，由$\\Delta\\alpha_{m \\times 1}=W_{m\\times n} \\cdot \\beta_{n\\times 1}$得到\n",
    "$$\\alpha'_{m\\times 1}=\\alpha^{pre}_{m\\times 1} - \\Delta\\alpha_{m\\times 1}=\\alpha_{m\\times 1}-W_{m\\times n} \\cdot \\beta_{n\\times 1}$$\n",
    "\n",
    "另外，item中有一些特殊的节点为源节点$s=\\alpha_{m\\times 1} \\odot Ms_{m \\times 1}$，其中$Ms_{m \\times 1}$为标示源节点的掩码向量。源节点的需求不应该由formula产出，但是要累计计算资源需求。即\n",
    "$$s_{m \\times 1}=s^{pre}_{m \\times 1}+\\alpha'_{m\\times 1} \\odot Ms_{m \\times 1}$$\n",
    "$$\\alpha^{suf}_{m\\times 1}=\\alpha'_{m\\times 1} \\odot (1-Ms_{m \\times 1})$$\n",
    "#### 归纳建模\n",
    "综上所述，已知边的权重矩阵为$W_{m\\times n}$，标示源节点的掩码矩阵为$Ms_{m \\times 1}\\in \\{0,1\\}^{m\\times 1}$，初始化需求供应矩阵为$\\alpha^0_{m\\times 1}$，建模方案如下：\n",
    "$$\\begin{aligned}\n",
    "init:&\\\\\n",
    "&W_{m\\times n} \\in R^{m\\times n} \\quad &(生产权重矩阵)\\\\\n",
    "&Ms_{m \\times 1}\\in \\{0,1\\}^{m\\times 1} \\quad &(物资的源节点掩码矩阵)\\\\\n",
    "&M_{m\\times n}=\\mathbb{I}(W_{m\\times n}>0) \\in \\{0,1\\}^{m\\times n}\\quad &(生产权重的供应掩码矩阵)\\\\\\\n",
    "&Ma_{m \\times 1}=1-Ms_{m \\times 1}\\quad &(物资的非源节点掩码矩阵)\\\\\n",
    "&Mp_{m\\times n}=(1−M_{m\\times n})\\odot (-epsilon)\\quad &(配方的分配概率掩码矩阵)\\\\\n",
    "&Wb_{m\\times n}= \\frac{1}{W_{m\\times n} + epsilon \\odot \\mathbb{I}(W_{m\\times n}=0)}\\quad &(倒数生产权重矩阵)\\\\\n",
    "&\\alpha^0_{m\\times 1} \\in R^{m\\times 1} \\quad &(初始需求供应矩阵)\\\\\n",
    "&s^0_{m \\times 1}=\\alpha^0_{m\\times 1} \\odot Ms_{m \\times 1}\\quad &(初始的源节点累计需求矩阵)\\\\\n",
    "......&\\\\\n",
    "layer^i:&\\\\\n",
    "&\\alpha^{pre}_{m\\times 1}\\in R^{m\\times 1} \\quad &(由上一层的 \\alpha^i_{m\\times 1} 输入)\\\\\n",
    "&s^{pre}_{m \\times 1}\\in R^{m\\times 1} \\quad &(由上一层的 s^i_{m \\times 1} 输入)\\\\\n",
    "\n",
    "&A^i_{m\\times n}\\in R^{m\\times n} \\quad &(配方的分配权重矩阵，被训练参数)\\\\\n",
    "&P^i_{m\\times n}=softmax(A^i_{m\\times n}+Mp_{m\\times n}, dim=1) \\odot M_{m\\times n} \\quad &(配方的分配概率矩阵)\\\\\n",
    "&X_{m\\times n}=ReLU(\\alpha^{pre}_{m\\times 1}) \\odot P^i_{m\\times n} \\odot Wb_{m\\times n}\\quad &(物资对配方的需求强度矩阵)\\\\\n",
    "&\\beta^i_{n\\times 1}= maxcol(X) \\quad &(配方的需求矩阵)\\\\\n",
    "&\\Delta\\alpha_{m\\times 1}=W_{m\\times n} \\cdot \\beta^i_{n\\times 1}\\quad &(本层生产处理的的物资变化量)\\\\\n",
    "&\\alpha^i_{m\\times 1}=\\alpha^{pre}_{m\\times 1} - \\Delta\\alpha_{m\\times 1} \\odot Ma_{m \\times 1}\\quad &(计算改变后的需求供应矩阵)\\\\\n",
    "&s^i_{m \\times 1}=s^{pre}_{m \\times 1}+\\Delta\\alpha_{m\\times 1} \\odot Ms_{m \\times 1}\\quad &(提取累加源节点需求)\\\\\n",
    "loss:&\\\\\n",
    "&Loss=Loss_{source}(s^i_{m \\times 1})+Loss_{unsat}(ReLU(−\\alpha^i_{m\\times 1}))\n",
    "\\end{aligned}$$\n",
    "\n",
    "#### 复盘总结\n",
    "针对以上建模，我使用多层网络去训练最优解，其中损失函数由最终&s^i_{m \\times 1}$的基础资源的消耗损失和$ReLU(\\alpha^i_{m\\times 1})$的需求未满足损失，但是发现需求未满足损失无法下降。\n",
    "\n",
    "总结原因是因为下游产物的需求满足往往会产生更多的上游产物的需求，所以此时在梯度上会趋向不满足下游产物的需求，从而导致需求未满足损失无法下降，另外在满足需求时，也会导致基础资源的消耗损失增加。\n",
    "\n",
    "### 思路2 资源顺推产出\n",
    "#### 推导过程\n",
    "\n",
    "#### 归纳建模\n",
    "已知边的权重矩阵为$W_{m\\times n}$，目标产出的产物比例矩阵$Wa^0_{m\\times 1} \\in R_+^{m\\times 1}$，初始的资源存量矩阵为$\\alpha^0_{m \\times 1}\\in R_+^{m\\times 1}$，建模方案如下：\n",
    "$$\\begin{aligned}\n",
    "init:&\\\\\n",
    "&\\alpha^0_{m \\times 1}\\in R_+^{m\\times 1} \\quad &(初始资源存量矩阵)\\\\\n",
    "&Wa_{m\\times 1} \\in R_+^{m\\times 1} \\quad &(目标产物的产物权重矩阵)\\\\\n",
    "\n",
    "&W_{m\\times n} \\in R^{m\\times n} \\quad &(生产权重矩阵)\\\\\n",
    "&M_{m\\times n}=\\mathbb{I}(W_{m\\times n}<0) \\in \\{0,1\\}^{m\\times n}\\quad &(生产权重的需求掩码矩阵)\\\\\n",
    "&Mp_{m\\times n}=(1−M_{m\\times n})\\odot (-epsilon)\\quad &(配方的分配概率掩码矩阵)\\\\\n",
    "&Wb_{m\\times n}= \\frac{1}{W_{m\\times n} + epsilon \\odot \\mathbb{I}(W_{m\\times n}=0)}\\quad &(倒数生产权重矩阵)\\\\\n",
    "\n",
    "......&\\\\\n",
    "layer^i:&\\\\\n",
    "&\\alpha^{pre}_{m\\times 1}\\in R_+^{m\\times 1} \\quad &(由上一层的 \\alpha^i_{m\\times 1} 输入)\\\\\n",
    "&A^i_{m\\times n}\\in R^{m\\times n} \\quad &(配方的分配权重矩阵，被训练参数)\\\\\n",
    "&P^i_{m\\times n}=softmax(A^i_{m\\times n}+Mp_{m\\times n}, dim=1) \\odot M_{m\\times n} \\quad &(配方的分配概率矩阵)\\\\\n",
    "&X_{m\\times n}=-ReLU(\\alpha^{pre}_{m\\times 1}) \\odot P^i_{m\\times n} \\odot Wb_{m\\times n}\\quad &(物资对配方的供应强度矩阵)\\\\\n",
    "&\\beta^i_{n\\times 1}= mincol(X) \\quad &(配方的供应矩阵)\\\\\n",
    "&\\Delta\\alpha_{m\\times 1}=W_{m\\times n} \\cdot \\beta^i_{n\\times 1}\\quad &(本层生产处理的的物资变化量)\\\\\n",
    "&\\alpha^i_{m\\times 1}=\\alpha^{pre}_{m\\times 1} + \\Delta\\alpha_{m\\times 1}\\quad &(计算改变后的资源存量矩阵)\\\\\n",
    "loss:&\\\\\n",
    "&Loss=Loss_{obj}(-\\alpha^i_{m\\times 1} \\odot Wa_{m\\times 1})\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当前使用设备：cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bio-24/projects/local/envs/dev/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import decimal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from factorio.satisfactory.formula import read_formula, parse_recipe_graph, parse_item, is_base_type, device\n",
    "\n",
    "\n",
    "def print_item_weights(item_weights, idx2item: dict, cut=0.01):\n",
    "    cut_str = str(cut).rstrip('0').rstrip('.') if '.' in str(cut) else str(cut)\n",
    "    d = decimal.Decimal(cut_str)\n",
    "    sign, digits, exponent = d.as_tuple()\n",
    "    decimal_places = max(0, -int(exponent))\n",
    "    \n",
    "    # 步骤3：需要保留的位数 = 有效小数位数 + 1（或直接返回有效小数位数）\n",
    "    needed_places = decimal_places + 1\n",
    "    for idx in range(len(item_weights)):\n",
    "        item_name = idx2item[idx]\n",
    "        weight = np.round(item_weights[idx], needed_places)\n",
    "        if np.abs(weight) > cut:\n",
    "            print(f\"  {item_name}: {weight}\")\n",
    "\n",
    "     \n",
    "     \n",
    "class RecipeGNN_V4(nn.Module):\n",
    "    \"\"\"\n",
    "    配方生产网络：基于item-formula双节点类型的多层传播网络。\n",
    "    item（资源存量）→formula（配方）→item（资源存量更新）\n",
    "    \"\"\"\n",
    "    def __init__(self, G: nx.DiGraph, target_dict: dict, source_dict: dict,\n",
    "                 num_layers: int=9,\n",
    "                 epsilon=1e-8, device=device, dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.G = G\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.parse_recipe_graph(weight = \"speed\")\n",
    "          \n",
    "        self.init_constants()\n",
    "        self.init_target_weight(target_dict=target_dict)\n",
    "        self.init_source_weight(source_dict=source_dict)\n",
    "        # 可训练矩阵A^i（每层独立，按需扩展）\n",
    "        self.init_layer(num_layers)\n",
    "        # self.final_formula_weights = torch.zeros([len(self.formula_nodes)], dtype=dtype, device=device)\n",
    "        # self.final_item_weights = torch.zeros([len(self.item_nodes)], dtype=dtype, device=device)\n",
    "\n",
    "    \n",
    "    def parse_recipe_graph(self, weight = \"speed\"):\n",
    "        (\n",
    "            self.raw_weight_matrix,\n",
    "            self.item_nodes, self.formula_nodes,\n",
    "            self.item2idx, self.formula2idx,\n",
    "            self.idx2item, self.idx2formula\n",
    "        ) = parse_recipe_graph(self.G, weight = weight)\n",
    "        \n",
    "    \n",
    "    def init_layer(self, num_layers: int):\n",
    "        \"\"\"新增一层的可训练矩阵A^i\"\"\"\n",
    "        self.A_layers = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn([len(self.item_nodes), len(self.formula_nodes)], dtype=self.dtype, device=self.device)) for _ in range(num_layers) # 初始化可训练参数，可自定义\n",
    "        ])\n",
    "    \n",
    "    def init_target_weight(self, target_dict: dict):\n",
    "        target_weight = torch.zeros(len(self.item_nodes), requires_grad=False, dtype=self.dtype, device=self.device)\n",
    "        for key in target_dict:\n",
    "            target_weight[self.item2idx[key]] = target_dict[key]\n",
    "        self.target_weight = target_weight\n",
    "        \n",
    "    def init_source_weight(self, source_dict: dict = {}):\n",
    "        source_weight = torch.zeros(len(self.item_nodes), requires_grad=False, dtype=self.dtype, device=self.device)\n",
    "        for key in source_dict:\n",
    "            source_weight[self.item2idx[key]] = source_dict[key]\n",
    "        self.alpha_0 = source_weight\n",
    "        \n",
    "    def init_constants(self):\n",
    "        \"\"\"\n",
    "        初始化所有常量（仅需调用一次）\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "        dtype = self.dtype\n",
    "        epsilon = self.epsilon\n",
    "        \n",
    "        self.fixed_weight_matrix = torch.tensor(self.raw_weight_matrix, requires_grad=False, dtype=dtype, device=device) \n",
    "        # 边掩码矩阵 M = I(W<0) ，获取 item -> formula 的有效边\n",
    "        self.weight_mask = (self.fixed_weight_matrix < 0).float()\n",
    "        # 分配权重的掩码权重矩阵 Mp = (1-M) * (-inf) \n",
    "        # 将 item -> formula 的无效边相关的矩阵设置为 -inf\n",
    "        self.invalid_mask_weight = torch.where(self.weight_mask.bool(), 0, -torch.inf)\n",
    "        # 3. 倒数权重矩阵 Wb = 1 / max(W, epsilon) ，计算 item 的 formula 需求\n",
    "        self.reciprocal_weight_matrix = 1.0 / (self.fixed_weight_matrix + epsilon * (self.fixed_weight_matrix == 0).float())\n",
    "        \n",
    "    \n",
    "    def single_layer_forward(self, alpha_prev: torch.Tensor, layer_idx):\n",
    "        \"\"\"\n",
    "        单轮layer_i前向计算（仅处理可变部分）\n",
    "            参数：\n",
    "                alpha_prev: (m,1) 上一轮item权重 α^{i-1}\n",
    "                layer_idx: int 当前层索引（从0开始）\n",
    "            返回：\n",
    "                alpha_i: (m,1) 非源节点item权重 α^i\n",
    "                s_increment: (m,1) 源节点资源增量（用于累计）\n",
    "                beta_i: (n,1) 当前层配方权重\n",
    "                P_i: 当前层配方分配概率矩阵\n",
    "        \"\"\"\n",
    "        alpha_prev = alpha_prev.unsqueeze(1)\n",
    "        # 1. 获取当前层可训练矩阵A^i\n",
    "        A_i = self.A_layers[layer_idx]\n",
    "        \n",
    "        # 2. 计算P^i = M ⊙ softmax(A^i + Mp, dim=1)\n",
    "        P_i = self.weight_mask * F.softmax(A_i + self.invalid_mask_weight, dim=1).nan_to_num(nan=0)\n",
    "        # 3. 计算beta^i = maxcol(α_prev ⊙ P_i ⊙ Wb)\n",
    "        X = F.relu(alpha_prev) * P_i * self.reciprocal_weight_matrix + self.invalid_mask_weight\n",
    "        X = torch.nan_to_num(X, nan=-torch.inf, neginf=-torch.inf)\n",
    "        beta_i = X.max(dim=0, keepdim=True)[0].T  # maxcol\n",
    "        beta_i = -torch.nan_to_num(beta_i, neginf=0)\n",
    "        # 4. 计算alpha' = ReLU(α_prev - W·β^i)\n",
    "        delta_alpha = self.fixed_weight_matrix @ beta_i  # W是init_constants中保存的原始矩阵\n",
    "        alpha_i = alpha_prev + delta_alpha\n",
    "        \n",
    "        return alpha_i.squeeze(1), beta_i, X, P_i\n",
    "    \n",
    "    def forward(self, alpha_0: torch.Tensor):\n",
    "        \"\"\"\n",
    "        完整前向传播（含初始化+多轮计算）\n",
    "        参数：\n",
    "            alpha_0: (m,1) 初始资源存量\n",
    "        返回：\n",
    "            resource_need: alpha_prev + s_prev\n",
    "            layer_list[\"alpha\": alpha_i, \"s\": s_i, \"beta\": beta_i, \"P\": P_i]\n",
    "        \"\"\"\n",
    "        \n",
    "        # 4. 多轮传播迭代\n",
    "        num_layers = len(self.A_layers)\n",
    "        alpha_prev = alpha_0\n",
    "        layer_list = []\n",
    "        beta_list = []\n",
    "        for i in range(num_layers):\n",
    "            # 单轮层计算（仅处理可变参数）\n",
    "            alpha_i, beta_i, contribution, P_i = self.single_layer_forward(\n",
    "                alpha_prev, layer_idx=i\n",
    "            )\n",
    "            beta_list.append(beta_i)\n",
    "            \n",
    "            # 保存结果\n",
    "            layer_list.append({\n",
    "                \"alpha\": alpha_i, \"beta\": beta_i, \"X\": contribution, \"P\": P_i\n",
    "            })\n",
    "\n",
    "            # 更新迭代变量\n",
    "            alpha_prev = alpha_i\n",
    "            \n",
    "        self.final_formula_weights = torch.cat(beta_list, dim=1).sum(dim=1)\n",
    "        self.final_item_weights = (self.fixed_weight_matrix @ self.final_formula_weights.unsqueeze(1)).squeeze(1)\n",
    "        self.resource, self.layer_list = alpha_prev, layer_list\n",
    "        return self.resource, layer_list\n",
    "\n",
    "    def print_final_formula_weights(self, cut=0.001):\n",
    "        final_formula_weights = self.final_formula_weights.cpu().detach().numpy()\n",
    "        print(\"\\n最终配方权重：\")\n",
    "        print_item_weights(final_formula_weights, self.idx2formula, cut)\n",
    "    \n",
    "\n",
    "        \n",
    "    def print_final_item_weights(self, cut=0.01):\n",
    "        final_item_weights = self.final_item_weights.cpu().detach().numpy()\n",
    "        print(\"\\n最终物料权重：\")\n",
    "        print_item_weights(final_item_weights, self.idx2item, cut)\n",
    "\n",
    "def recipe_loss_fn(\n",
    "    final_item_weights: torch.Tensor,\n",
    "    target_weights: torch.Tensor\n",
    ") -> tuple[torch.Tensor, dict]:\n",
    "    \"\"\"\n",
    "    多目标损失函数设计\n",
    "    参数：\n",
    "        lambda_target: 目标物料的损失权重（优先级最高，指数递增）\n",
    "        lambda_source_max: 基础资源最大化的损失权重（线性递增）\n",
    "        lambda_other_pos: 其他资源大于0的损失权重（线性递增）\n",
    "        target_num: 目标物料的数量\n",
    "    返回：\n",
    "        total_loss: 总损失（可反向传播优化）\n",
    "        dict: loss_source_max loss_other_pos\n",
    "    \"\"\"\n",
    "    \n",
    "    loss_target_max = -torch.sum(final_item_weights * target_weights)\n",
    "    total_loss = (\n",
    "        loss_target_max\n",
    "    )\n",
    "\n",
    "    # 返回总损失及各分项损失（方便监控）\n",
    "    return total_loss, {\n",
    "        'loss_source_max': loss_target_max.cpu().item()\n",
    "    }\n",
    "    \n",
    "def train_recipe_gnn(model: RecipeGNN_V4,\n",
    "        source_dict: dict | None = None,\n",
    "        target_dict: dict | None = None,\n",
    "        epochs: int = 1000,\n",
    "        lr: float = 0.01,\n",
    "        print_interval: int = 100,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        训练配方GNN模型\n",
    "        参数：\n",
    "            target_base_ratio: 基础资源的目标配比（numpy数组，长度=基础资源数量）\n",
    "            epochs: 训练轮数\n",
    "            lr: 学习率\n",
    "            print_interval: 日志打印间隔\n",
    "            \"\"\"\n",
    "        # 1. 配置优化器（仅优化可训练参数 formula_weights）\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        if source_dict is not None:\n",
    "            model.init_source_weight(source_dict)\n",
    "        if target_dict is not None:\n",
    "            model.init_target_weight(target_dict)\n",
    "        # 3. 训练循环\n",
    "        model.train()  # 切换到训练模式\n",
    "        for epoch in range(epochs):\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播：获取资源增减量\n",
    "            resource, layer_list = model.forward(alpha_0=model.alpha_0)\n",
    "\n",
    "            # 计算损失\n",
    "            total_loss, loss_details = recipe_loss_fn(\n",
    "                model.resource,\n",
    "                target_weights=model.target_weight\n",
    "            )\n",
    "\n",
    "            model.total_loss = total_loss\n",
    "            # 反向传播 + 参数更新\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 打印训练日志\n",
    "            if (epoch + 1) % print_interval == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "                print(f\"  总损失：{total_loss.item():.4f}\")\n",
    "                # 打印关键指标\n",
    "                target_change = model.final_item_weights[(model.target_weight > 0)]\n",
    "                target_change = target_change.cpu().detach().numpy()\n",
    "                source_changes = model.final_item_weights[(model.alpha_0 > 0)]\n",
    "                source_changes = source_changes.cpu().detach().numpy()\n",
    "                \n",
    "                # 避免除0错误\n",
    "                if np.sum(np.abs(source_changes)) > 1e-8:\n",
    "                    base_ratio = source_changes / np.sum(np.abs(source_changes))\n",
    "                else:\n",
    "                    base_ratio = source_changes\n",
    "                print(f\"  目标物料增减量：{target_change.round(4)}\")\n",
    "                print(f\"  基础资源增减量：{source_changes.round(2)}\")\n",
    "                print(f\"  基础资源当前配比：{base_ratio.round(4)}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        print(\"训练完成！\")\n",
    "        model.print_final_formula_weights(cut=0.001)\n",
    "        model.print_final_item_weights(cut=0.01)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    g = read_formula()\n",
    "\n",
    "    num_layers = 20  # 传播层数\n",
    "    epsilon = 1e-8  # 数值安全常数\n",
    "    \n",
    "    source_weight={\n",
    "        \"水\": 1e8, \"激发态光子物质\": 1e8, \"铁矿石\": 921, \"石灰石\": 693, \"铜矿石\": 369, \"钦金矿石\": 150, \"煤\": 423,\n",
    "        \"原油\": 126, \"硫磺\": 108, \"铝土矿\": 123, \"粗石英\": 135, \"铀\": 21, \"SAM物质\": 102, \"氮气\": 120\n",
    "    }\n",
    "    \n",
    "    # 3. 初始化模型\n",
    "\n",
    "    source_weight = {k:v * 1e3 for k,v in source_weight.items()}\n",
    "    target_weight={\n",
    "        \"封压方块\": 1,\n",
    "        \"镄燃料棒\": 2\n",
    "    }\n",
    "    model = RecipeGNN_V4(g, target_dict=target_weight, source_dict=source_weight, num_layers=num_layers, epsilon=epsilon)\n",
    "    \n",
    "    train_recipe_gnn(\n",
    "        model=model,\n",
    "        source_dict=source_weight,\n",
    "        target_dict=target_weight,\n",
    "        epochs=1000,\n",
    "        lr=0.01,\n",
    "        print_interval=100\n",
    "    )\n",
    "    \n",
    "    # 网络传递的系统误差\n",
    "    sys_loss = torch.sqrt(torch.nn.functional.mse_loss(model.final_item_weights + model.alpha_0,  model.resource))/ torch.mean(model.resource)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    resource, layer_list = model.forward(alpha_0=model.alpha_0)\n",
    "\n",
    "    total_loss, loss_details = recipe_loss_fn(\n",
    "        resource,\n",
    "        target_weights=model.target_weight,\n",
    "    )\n",
    "\n",
    "    torch.autograd.grad(outputs=total_loss, retain_graph=True, inputs=model.layer_list[-1][\"beta\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (155) must match the size of tensor b (228) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 308\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# 3. 初始化模型\u001b[39;00m\n\u001b[32m    306\u001b[39m model = RecipeGNN(g, target_dict=target_weight, source_weight=source_weight, num_layers=num_layers, epsilon=epsilon)\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_recipe_gnn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43msource_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msource_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_interval\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_source_max\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlambda_other_pos\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m    315\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 245\u001b[39m, in \u001b[36mRecipeGNN.train_recipe_gnn\u001b[39m\u001b[34m(self, source_weight, epochs, lr, print_interval, lambda_source_max, lambda_other_pos)\u001b[39m\n\u001b[32m    242\u001b[39m optimizer.zero_grad()\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# 前向传播：获取资源增减量\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m resource_change, layer_list = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha_0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43malpha_0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms_0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43ms_0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m \u001b[38;5;66;03m# 计算损失\u001b[39;00m\n\u001b[32m    248\u001b[39m total_loss, loss_details = model.recipe_loss_fn(\n\u001b[32m    249\u001b[39m     resource_change,\n\u001b[32m    250\u001b[39m     lambda_source_max = lambda_source_max,     \u001b[38;5;66;03m# 基础资源最大化的损失权重\u001b[39;00m\n\u001b[32m    251\u001b[39m     lambda_other_pos = lambda_other_pos,     \u001b[38;5;66;03m# 其他资源大于0的损失权重\u001b[39;00m\n\u001b[32m    252\u001b[39m )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 154\u001b[39m, in \u001b[36mRecipeGNN.forward\u001b[39m\u001b[34m(self, alpha_0, s_0)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;28mself\u001b[39m.final_formula_weights.zero_()\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers):\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# 单轮层计算（仅处理可变参数）\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     alpha_i, s_inc, beta_i, P_i = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msingle_layer_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43malpha_prev\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# 累计源节点资源 s^i = s^{i-1} + s_inc\u001b[39;00m\n\u001b[32m    159\u001b[39m     s_i = s_prev + s_inc\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36mRecipeGNN.single_layer_forward\u001b[39m\u001b[34m(self, alpha_prev, layer_idx)\u001b[39m\n\u001b[32m    119\u001b[39m P_i = \u001b[38;5;28mself\u001b[39m.weight_mask * F.softmax(A_i + \u001b[38;5;28mself\u001b[39m.probability_mask, dim=\u001b[32m1\u001b[39m)\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# 3. 计算beta^i = maxcol(α_prev ⊙ P_i ⊙ Wb)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m contribution = \u001b[43malpha_prev\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mP_i\u001b[49m * \u001b[38;5;28mself\u001b[39m.reciprocal_weight_matrix  \u001b[38;5;66;03m# 哈达玛积简化\u001b[39;00m\n\u001b[32m    124\u001b[39m beta_i: torch.Tensor = contribution.max(dim=\u001b[32m0\u001b[39m, keepdim=\u001b[38;5;28;01mTrue\u001b[39;00m)[\u001b[32m0\u001b[39m].T  \u001b[38;5;66;03m# maxcol\u001b[39;00m\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# 4. 计算alpha' = ReLU(α_prev - W·β^i)\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (155) must match the size of tensor b (228) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import decimal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "from factorio.satisfactory.formula import read_formula, parse_recipe_graph, parse_item, is_base_type, device\n",
    "\n",
    "\n",
    "def print_item_weights(item_weights, idx2item: dict, cut=0.01):\n",
    "    cut_str = str(cut).rstrip('0').rstrip('.') if '.' in str(cut) else str(cut)\n",
    "    d = decimal.Decimal(cut_str)\n",
    "    sign, digits, exponent = d.as_tuple()\n",
    "    decimal_places = max(0, -int(exponent))\n",
    "    \n",
    "    # 步骤3：需要保留的位数 = 有效小数位数 + 1（或直接返回有效小数位数）\n",
    "    needed_places = decimal_places + 1\n",
    "    for idx in range(len(item_weights)):\n",
    "        item_name = idx2item[idx]\n",
    "        weight = np.round(item_weights[idx], needed_places)\n",
    "        if np.abs(weight) > cut:\n",
    "            print(f\"  {item_name}: {weight}\")\n",
    "\n",
    "           \n",
    "class RecipeGNN(nn.Module):\n",
    "    \"\"\"\n",
    "    配方生产网络：基于item-formula双节点类型的多层传播网络。\n",
    "    item（物资）→formula（配方）→item更新→源节点资源累计\n",
    "    \"\"\"\n",
    "    def __init__(self, G: nx.DiGraph, target_dict: dict, source_weight: dict,\n",
    "                 num_layers: int=9,\n",
    "                 epsilon=1e-8, device=device, dtype=torch.float32,\n",
    "                 is_source: Callable[[nx.DiGraph, str], bool] = is_base_type):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.dtype = dtype\n",
    "        self.G = G\n",
    "        self.epsilon = epsilon\n",
    "        \n",
    "        self.parse_recipe_graph(weight = \"speed\")\n",
    "        \n",
    "        self.parse_item(target_dict=target_dict, is_source=is_source)\n",
    "        \n",
    "        self.init_constants()\n",
    "        self.init_source_weight(source_weight=source_weight)\n",
    "        # 可训练矩阵A^i（每层独立，按需扩展）\n",
    "        self.init_layer(num_layers)\n",
    "        # self.final_formula_weights = torch.zeros([len(self.formula_nodes)], dtype=dtype, device=device)\n",
    "        # self.final_item_weights = torch.zeros([len(self.item_nodes)], dtype=dtype, device=device)\n",
    "\n",
    "    \n",
    "    def parse_recipe_graph(self, weight = \"speed\"):\n",
    "        (\n",
    "            self.raw_weight_matrix,\n",
    "            self.item_nodes, self.formula_nodes,\n",
    "            self.item2idx, self.formula2idx,\n",
    "            self.idx2item, self.idx2formula\n",
    "        ) = parse_recipe_graph(self.G, weight = weight)\n",
    "        \n",
    "    \n",
    "    def parse_item(self, target_dict: dict, is_source = is_base_type):\n",
    "        (\n",
    "            self.raw_target_weights, self.source_items, self.source_idxs,\n",
    "            self.target_items, self.target_idxs, self.other_items, self.other_items_idx\n",
    "        ) = parse_item(self.G, item_nodes=self.item_nodes, item2idx=self.item2idx,\n",
    "                       target_dict=target_dict, is_source=is_source)\n",
    "    \n",
    "    def init_layer(self, num_layers: int):\n",
    "        \"\"\"新增一层的可训练矩阵A^i\"\"\"\n",
    "        self.A_layers = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn([len(self.item_nodes), len(self.formula_nodes)], dtype=self.dtype, device=self.device)) for _ in range(num_layers) # 初始化可训练参数，可自定义\n",
    "        ])\n",
    "        \n",
    "    def init_source_weight(self, source_weight: dict = {}, default = 1):\n",
    "        min_val, max_val = 0, 1\n",
    "        target_source_weight = torch.zeros(len(self.item_nodes), requires_grad=False, dtype=self.dtype, device=self.device)\n",
    "        for key in self.source_items:\n",
    "            if key in source_weight:\n",
    "                target_source_weight[self.item2idx[key]] = source_weight[key]\n",
    "            else:\n",
    "                target_source_weight[self.item2idx[key]] = default\n",
    "        # 计算当前权重的最小值和最大值（添加epsilon避免除0）\n",
    "        weight_min = torch.clamp(torch.min(target_source_weight), min=self.epsilon)\n",
    "        weight_max = torch.clamp(torch.max(target_source_weight), min=self.epsilon)\n",
    "        # 最小-最大缩放：将权重缩放到 [min_val, max_val]\n",
    "        scaled_weight = (target_source_weight - weight_min) / (weight_max - weight_min) * (max_val - min_val) + min_val\n",
    "        self.source_weight = source_weight\n",
    "        self.scaled_source_weight = scaled_weight\n",
    "        \n",
    "    def init_constants(self):\n",
    "        \"\"\"\n",
    "        初始化所有常量（仅需调用一次）\n",
    "        \"\"\"\n",
    "        device = self.device\n",
    "        dtype = self.dtype\n",
    "        epsilon = self.epsilon\n",
    "        \n",
    "        self.fixed_weight_matrix = torch.tensor(self.raw_weight_matrix, requires_grad=False, dtype=dtype, device=device) \n",
    "        self.source_mask = torch.zeros([len(self.item_nodes)], requires_grad=False, dtype=dtype, device=device)\n",
    "        self.source_mask[self.source_idxs] = 1.0\n",
    "        self.target_weights = torch.tensor(self.raw_target_weights, requires_grad=False, dtype=dtype, device=device)\n",
    "        # 1. 边掩码矩阵 M = I(W>0) ，获取 item -> formula 的有效边\n",
    "        self.weight_mask = (self.fixed_weight_matrix > 0).float()\n",
    "        \n",
    "        # 2. 概率掩码矩阵 Mp = (1-M) * (-1/epsilon) ，获取 item -> formula 的有效概率选择\n",
    "        minus_1_over_epsilon = -1.0 / epsilon\n",
    "        self.probability_mask = (1 - self.weight_mask) * minus_1_over_epsilon\n",
    "        \n",
    "        # 3. 倒数权重矩阵 Wb = 1 / max(W, epsilon) ，计算 item 的 formula 需求\n",
    "        self.reciprocal_weight_matrix = 1.0 / torch.max(self.fixed_weight_matrix, torch.tensor(epsilon, requires_grad=False, dtype=dtype, device=device))\n",
    "        \n",
    "        # 4. 非源节点掩码 Ma = 1 - Ms\n",
    "        self.normal_mask = (1 - self.source_mask).float()\n",
    "        \n",
    "        self.alpha_0 = torch.tensor(self.raw_target_weights, requires_grad=False, dtype=dtype, device=device)\n",
    "        self.s_0 = torch.zeros([len(self.item_nodes)], requires_grad=False, dtype=dtype, device=device)\n",
    "        self.s_0 = self.s_0 + self.alpha_0 * self.source_mask\n",
    "        \n",
    "    \n",
    "    def single_layer_forward(self, alpha_prev: torch.Tensor, layer_idx):\n",
    "        \"\"\"\n",
    "        单轮layer_i前向计算（仅处理可变部分）\n",
    "            参数：\n",
    "                alpha_prev: (m,1) 上一轮item权重 α^{i-1}\n",
    "                layer_idx: int 当前层索引（从0开始）\n",
    "            返回：\n",
    "                alpha_i: (m,1) 非源节点item权重 α^i\n",
    "                s_increment: (m,1) 源节点资源增量（用于累计）\n",
    "                beta_i: (n,1) 当前层配方权重\n",
    "                P_i: 当前层配方分配概率矩阵\n",
    "        \"\"\"\n",
    "        alpha_prev = alpha_prev.unsqueeze(1)\n",
    "        # 1. 获取当前层可训练矩阵A^i\n",
    "        A_i = self.A_layers[layer_idx]\n",
    "        \n",
    "        # 2. 计算P^i = M ⊙ softmax(A^i + Mp, dim=1)\n",
    "        P_i = self.weight_mask * F.softmax(A_i + self.probability_mask, dim=1)\n",
    "        \n",
    "        # 3. 计算beta^i = maxcol(α_prev ⊙ P_i ⊙ Wb)\n",
    "        contribution = F.relu(alpha_prev) * P_i * self.reciprocal_weight_matrix  # 哈达玛积简化\n",
    "        \n",
    "        beta_i: torch.Tensor = contribution.max(dim=0, keepdim=True)[0].T  # maxcol\n",
    "        # 4. 计算alpha' = ReLU(α_prev - W·β^i)\n",
    "        delta_alpha = self.fixed_weight_matrix @ beta_i  # W是init_constants中保存的原始矩阵\n",
    "        alpha_prime = (alpha_prev - delta_alpha).squeeze(1)\n",
    "        \n",
    "        # 5. 源节点资源增量 + 非源节点alpha_i\n",
    "        s_increment = alpha_prime * self.source_mask\n",
    "        alpha_i = alpha_prime * self.normal_mask\n",
    "        \n",
    "        return alpha_i, s_increment, beta_i, P_i\n",
    "    \n",
    "    def forward(self, alpha_0: torch.Tensor, s_0: torch.Tensor):\n",
    "        \"\"\"\n",
    "        完整前向传播（含初始化+多轮计算）\n",
    "        参数：\n",
    "            alpha_0: (m,1) 初始item需求\n",
    "            s_0: (m,1) 初始源节点资源需求\n",
    "        返回：\n",
    "            resource_need: alpha_prev + s_prev\n",
    "            layer_list[\"alpha\": alpha_i, \"s\": s_i, \"beta\": beta_i, \"P\": P_i]\n",
    "        \"\"\"\n",
    "        \n",
    "        # 4. 多轮传播迭代\n",
    "        num_layers = len(self.A_layers)\n",
    "        alpha_prev = alpha_0\n",
    "        s_prev = s_0\n",
    "        layer_list = []\n",
    "        beta_list = []\n",
    "        for i in range(num_layers):\n",
    "            # 单轮层计算（仅处理可变参数）\n",
    "            alpha_i, s_inc, beta_i, P_i = self.single_layer_forward(\n",
    "                alpha_prev, layer_idx=i\n",
    "            )\n",
    "            beta_list.append(beta_i)\n",
    "            # 累计源节点资源 s^i = s^{i-1} + s_inc\n",
    "            s_i = s_prev + s_inc\n",
    "            \n",
    "            # 保存结果\n",
    "            layer_list.append({\n",
    "                \"alpha\": alpha_i, \"s\": s_i, \"beta\": beta_i, \"P\": P_i\n",
    "            })\n",
    "\n",
    "            # 更新迭代变量\n",
    "            alpha_prev = alpha_i\n",
    "            s_prev = s_i\n",
    "        self.final_formula_weights = torch.cat(beta_list, dim=1).sum(dim=1)\n",
    "        self.final_item_weights = (self.fixed_weight_matrix @ self.final_formula_weights.unsqueeze(1)).squeeze(1)\n",
    "        self.resource_need, self.layer_list = alpha_prev + s_prev, layer_list\n",
    "        self.layer_list = layer_list\n",
    "        return self.resource_need, layer_list\n",
    "\n",
    "    def print_final_formula_weights(self, cut=0.001):\n",
    "        final_formula_weights = self.final_formula_weights.cpu().detach().numpy()\n",
    "        print(\"\\n最终配方权重：\")\n",
    "        print_item_weights(final_formula_weights, self.idx2formula, cut)\n",
    "    \n",
    "\n",
    "        \n",
    "    def print_final_item_weights(self, cut=0.01):\n",
    "        final_item_weights = self.final_item_weights.cpu().detach().numpy()\n",
    "        print(\"\\n最终物料权重：\")\n",
    "        print_item_weights(final_item_weights, self.idx2item, cut)\n",
    "    \n",
    "def recipe_loss_fn(\n",
    "    final_item_weights: torch.Tensor,\n",
    "    scaled_source_weight: torch.Tensor,\n",
    "    other_items_idx,\n",
    "    lambda_source_max: float = 0.1,     # 基础资源最大化的损失权重\n",
    "    lambda_other_pos: float = 2.0,     # 其他资源大于0的损失权重\n",
    "    epsilon=1e-8,\n",
    ") -> tuple[torch.Tensor, dict]:\n",
    "    \"\"\"\n",
    "    多目标损失函数设计\n",
    "    参数：\n",
    "        lambda_target: 目标物料的损失权重（优先级最高，指数递增）\n",
    "        lambda_source_max: 基础资源最大化的损失权重（线性递增）\n",
    "        lambda_other_pos: 其他资源大于0的损失权重（线性递增）\n",
    "        target_num: 目标物料的数量\n",
    "    返回：\n",
    "        total_loss: 总损失（可反向传播优化）\n",
    "        dict: loss_source_max loss_other_pos\n",
    "    \"\"\"\n",
    "    # # -------------------------- 损失项1：基础资源尽可能消耗少 --------------------------\n",
    "    # # 提取基础资源的增减量 [len(source_resources),]\n",
    "    # source_change = final_item_weights * scaled_source_weight\n",
    "    # # 目标：因为source_change为负值表示消耗，所以应该最大化 source_change → 损失函数中最小化 (-source_change) 的均值（越大，损失越小）\n",
    "    # source_change_norm = torch.nn.functional.normalize(source_change, p=2, dim=0, eps=epsilon)\n",
    "    # # 步骤2：用归一化后的数值计算损失，梯度幅值将固定\n",
    "    # loss_source_max = -torch.sum(source_change_norm * scaled_source_weight)\n",
    "    \n",
    "    loss_source_max = -torch.sum(final_item_weights * scaled_source_weight)\n",
    "    # -------------------------- 损失项2：其他资源大于0（非基础、非目标） --------------------------\n",
    "    # 提取其他资源的索引：非基础 + 非目标\n",
    "\n",
    "    other_change = final_item_weights[other_items_idx]\n",
    "    \n",
    "    # 惩罚小于0的部分：使用ReLU的反向逻辑（若x<0，惩罚为-x；x≥0，惩罚为0）\n",
    "    loss_other_pos = torch.max(torch.nn.functional.relu(-other_change))  # other_change<0时，-other_change>0，产生惩罚\n",
    "\n",
    "    # -------------------------- 总损失：加权组合 --------------------------\n",
    "    total_loss = (\n",
    "        lambda_source_max * loss_source_max\n",
    "        + lambda_other_pos * loss_other_pos\n",
    "    )\n",
    "\n",
    "    # 返回总损失及各分项损失（方便监控）\n",
    "    return total_loss, {\n",
    "        'loss_source_max': loss_source_max.cpu().item(),\n",
    "        'loss_other_pos': loss_other_pos.cpu().item()\n",
    "    }\n",
    "    \n",
    "def train_recipe_gnn(model: RecipeGNN,\n",
    "        source_weight: dict | None = None,\n",
    "        epochs: int = 1000,\n",
    "        lr: float = 0.01,\n",
    "        print_interval: int = 100,\n",
    "        lambda_source_max = 0.1,     # 基础资源最大化的损失权重\n",
    "        lambda_other_pos = 10.0,     # 其他资源大于0的损失权重\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        训练配方GNN模型\n",
    "        参数：\n",
    "            target_base_ratio: 基础资源的目标配比（numpy数组，长度=基础资源数量）\n",
    "            epochs: 训练轮数\n",
    "            lr: 学习率\n",
    "            print_interval: 日志打印间隔\n",
    "            \"\"\"\n",
    "        # 1. 配置优化器（仅优化可训练参数 formula_weights）\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        if source_weight is not None:\n",
    "            model.init_source_weight(source_weight)\n",
    "        # 3. 训练循环\n",
    "        model.train()  # 切换到训练模式\n",
    "        for epoch in range(epochs):\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 前向传播：获取资源增减量\n",
    "            resource_need, layer_list = model.forward(alpha_0=model.alpha_0, s_0=model.s_0)\n",
    "\n",
    "            # 计算损失\n",
    "            total_loss, loss_details = recipe_loss_fn(\n",
    "                model.final_item_weights,\n",
    "                scaled_source_weight=model.scaled_source_weight,\n",
    "                other_items_idx=model.other_items_idx,\n",
    "                lambda_source_max = lambda_source_max,     # 基础资源最大化的损失权重\n",
    "                lambda_other_pos = lambda_other_pos,     # 其他资源大于0的损失权重\n",
    "            )\n",
    "\n",
    "            model.total_loss = total_loss\n",
    "            # 反向传播 + 参数更新\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 打印训练日志\n",
    "            if (epoch + 1) % print_interval == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}]\")\n",
    "                print(f\"  总损失：{total_loss.item():.4f}\")\n",
    "                print(f\"  基础资源最大化损失：{loss_details['loss_source_max']:.4f}\")\n",
    "                print(f\"  其他资源非负损失：{loss_details['loss_other_pos']:.4f}\")\n",
    "                # 打印关键指标\n",
    "                target_change = model.final_item_weights[model.target_idxs].cpu().detach().numpy()\n",
    "                source_changes = resource_need[model.source_idxs].cpu().detach().numpy()\n",
    "                \n",
    "                # 避免除0错误\n",
    "                if np.sum(np.abs(source_changes)) > 1e-8:\n",
    "                    base_ratio = source_changes / np.sum(np.abs(source_changes))\n",
    "                else:\n",
    "                    base_ratio = source_changes\n",
    "                print(f\"  目标物料增减量：{target_change.round(4)}\")\n",
    "                print(f\"  基础资源增减量：{source_changes.round(2)}\")\n",
    "                print(f\"  基础资源当前配比：{base_ratio.round(4)}\")\n",
    "                print(\"-\" * 50)\n",
    "\n",
    "        print(\"训练完成！\")\n",
    "        model.print_final_formula_weights(cut=0.001)\n",
    "        model.print_final_item_weights(cut=0.01)\n",
    "\n",
    "# -------------------------- 测试示例 --------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    g = read_formula()\n",
    "\n",
    "    num_layers = 20  # 传播层数\n",
    "    epsilon = 1e-8  # 数值安全常数\n",
    "    \n",
    "    source_weight={\n",
    "        \"水\": 0, \"激发态光子物质\": 0, \"铁矿石\": 1/921, \"石灰石\": 1/693, \"铜矿石\": 1/369, \"钦金矿石\": 1/150, \"煤\": 1/423,\n",
    "        \"原油\": 1/126, \"硫磺\": 1/108, \"铝土矿\": 1/123, \"粗石英\": 1/135, \"铀\": 1/21, \"SAM物质\": 1/102, \"氮气\": 1/120\n",
    "    }\n",
    "    target_weight={\n",
    "        \"封压方块\": 1,\n",
    "        \"镄燃料棒\": 2\n",
    "    }\n",
    "    \n",
    "    # 3. 初始化模型\n",
    "\n",
    "    \n",
    "    model = RecipeGNN(g, target_dict=target_weight, source_weight=source_weight, num_layers=num_layers, epsilon=epsilon)\n",
    "    \n",
    "    train_recipe_gnn(\n",
    "        model=model,\n",
    "        source_weight=source_weight,\n",
    "        epochs=1000,\n",
    "        lr=0.01,\n",
    "        print_interval=100,\n",
    "        lambda_source_max=0.01,\n",
    "        lambda_other_pos=100\n",
    "    )\n",
    "    \n",
    "    # 网络传递的系统误差\n",
    "    sys_loss = torch.sqrt(torch.nn.functional.mse_loss(model.final_item_weights,  -model.resource_need))/ torch.mean(model.resource_need)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    resource_need, layer_list = model.forward(alpha_0=model.alpha_0, s_0=model.s_0)\n",
    "\n",
    "    total_loss, loss_details = recipe_loss_fn(\n",
    "        -resource_need,\n",
    "        scaled_source_weight=model.scaled_source_weight,\n",
    "        other_items_idx=model.other_items_idx,\n",
    "        lambda_source_max = 1,     # 基础资源最大化的损失权重\n",
    "        lambda_other_pos = 1,     # 其他资源大于0的损失权重\n",
    "    )\n",
    "\n",
    "    torch.autograd.grad(outputs=total_loss, retain_graph=True, inputs=model.layer_list[-1][\"beta\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
