{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings\n",
    "# 忽略requests的安全警告（可选）\n",
    "# warnings.filterwarnings('ignore')\n",
    "default_headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "def deal_item(item: bs4.element.Tag):\n",
    "    text = item.get_text(strip=True)\n",
    "    match1 = re.search(r\"\\((.*?) / min\\)\", text)\n",
    "    speed = int(match1.group(1))\n",
    "    match2 = re.search(r\"(\\d+)x(.*)\", text[match1.end():])\n",
    "    num = int(match2.group(1))\n",
    "    name = match2.group(2)\n",
    "    return {\"name\": name, \"num\": num, \"speed\": speed}\n",
    "\n",
    "def deal_formula(formula_section: bs4.element.Tag):\n",
    "    formula_item = formula_section.find_all(\"div\", recursive=False)\n",
    "    info = formula_item[0].find_all(\"div\", recursive=False)\n",
    "    name = info[0].get_text(strip=True).replace(\"替代：\", \"\")\n",
    "    by = re.search(r\"\\((.*?)\\)\", info[1].get_text(strip=True)).group(1)\n",
    "    formula = formula_item[1].find_all(\"div\",class_=\"col-6\")\n",
    "    inputs = [deal_item(input) for input in formula[0].find_all(\"div\", recursive=False)]\n",
    "    outputs = [deal_item(output) for output in formula[1].find_all(\"div\", recursive=False)]\n",
    "    return {\"name\": name, \"by\": by, \"inputs\": inputs, \"outputs\": outputs}\n",
    "        \n",
    "        \n",
    "class SatisfactorySpider:\n",
    "    def __init__(self, headers = default_headers):\n",
    "        self.headers = headers\n",
    "        self.base_url = \"https://satisfactory-calculator.com/\"\n",
    "        self.items_path = {}\n",
    "        self.all_formula = {}\n",
    "    \n",
    "    def get_all_formula(self):\n",
    "        if not self.items_path:\n",
    "            self.get_items_list()\n",
    "        for item in self.items_path:\n",
    "            item_info = self.get_item_info(item)\n",
    "            self.all_formula[item] = item_info\n",
    "        return self.all_formula\n",
    "\n",
    "    def deal_items_html(self, soup: BeautifulSoup):\n",
    "        base_info = {}\n",
    "        main = soup.find(\"main\").find_all(\"div\", recursive=False)[1]\n",
    "        # info\n",
    "        media_body = main.find('div', class_='media-body')\n",
    "        base_info[\"描述\"] = media_body.find(\"div\", class_=\"card-body\").get_text(strip=True)\n",
    "        \n",
    "        ul_list = media_body.find_all('ul', class_='list-group')\n",
    "        base_info[\"类别\"] = ul_list[0].find(\"strong\").get_text(strip=True)\n",
    "        base_info[\"堆叠数量\"] = int(ul_list[1].find(\"strong\").get_text(strip=True))\n",
    "        base_info[\"资源槽点数\"] = int(ul_list[2].find(\"strong\").get_text(strip=True))\n",
    "        \n",
    "        # formula        \n",
    "        formula_all = main.find_all(\"div\", recursive=False)[2].find_all(\"div\", recursive=False)\n",
    "        formula_list = [deal_formula(formula_section) for formula_section in formula_all[0].find_all(\"div\",class_=\"card-body\")]\n",
    "        replace_formula_list = [deal_formula(formula_section) for formula_section in formula_all[1].find_all(\"div\",class_=\"card-body\")]\n",
    "        \n",
    "        return {\"base_info\": base_info, \"formula_list\": formula_list, \"replace_formula_list\": replace_formula_list}\n",
    "        \n",
    "    def get_item_info(self, item_name):\n",
    "        if item_name not in self.items_path:\n",
    "            return None\n",
    "        headers = self.headers\n",
    "        url = os.path.join(self.base_url + self.items_path[item_name])\n",
    "        timeout = 10\n",
    "        item_info = {}\n",
    "        \n",
    "        try:\n",
    "            # 1. 发送请求获取网页源码\n",
    "            response = requests.get(url, headers=headers, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            response.encoding = response.apparent_encoding  # 自动识别编码\n",
    "            soup = BeautifulSoup(response.text, 'lxml')  # lxml解析器更高效（需安装：pip install lxml）\n",
    "\n",
    "            try:\n",
    "                item_info = self.deal_items_html(soup)\n",
    "                item_info[\"base_info\"].update({\"url\": url, \"name\": item_name})\n",
    "                print(\"处理物品信息成功：\", item_name)\n",
    "            except Exception as e:\n",
    "                print(\"处理物品信息失败：\", item_name)\n",
    "                print(e)\n",
    "        except Exception as e:\n",
    "            print(\"获取物品信息失败：\", item_name)\n",
    "            print(e)\n",
    "        return item_info\n",
    "        \n",
    "    def get_items_list(self):\n",
    "        \"\"\"\n",
    "        获取物品列表页面中的所有链接（即所有物品的详细页面）\n",
    "        :return: dict[name, path] 所有物品链接列表，每个元素是一个字典，键为 name 值为 path \n",
    "        \"\"\"\n",
    "        pattern = \".*zh/items/detail/id/.*\"\n",
    "        url = os.path.join(self.base_url, \"zh/items\")\n",
    "        headers = self.headers\n",
    "        timeout = 10\n",
    "        pattern = re.compile(pattern)\n",
    "        items_path = {}\n",
    "        \n",
    "        try:\n",
    "            # 1. 发送请求获取网页源码\n",
    "            response = requests.get(url, headers=headers, timeout=timeout)\n",
    "            response.raise_for_status()  # 抛出HTTP错误（如404/500）\n",
    "            response.encoding = response.apparent_encoding  # 自动识别编码\n",
    "\n",
    "            # 2. 解析HTML\n",
    "            soup = BeautifulSoup(response.text, 'lxml')  # 也可用'lxml'（需先安装：pip install lxml）\n",
    "\n",
    "            # 3. 筛选href包含指定字符的a标签\n",
    "            # 遍历所有a标签\n",
    "            for a_tag in soup.find_all('a', href=True):  # href=True：只筛选有href属性的a标签\n",
    "                href = a_tag['href']\n",
    "                # 判断href是否包含目标字符（支持单个字符/多个字符）\n",
    "                match = pattern.match(href)\n",
    "                if match:\n",
    "                    # 4. 提取strong子元素的文本（兼容无strong的情况）\n",
    "                    strong_tag = a_tag.find('strong')  # 只找第一个strong\n",
    "                    strong_text = strong_tag.get_text(strip=True) if strong_tag else ''\n",
    "                    \n",
    "                    # 整理结果（处理相对路径/绝对路径）\n",
    "                    if strong_text:\n",
    "                        if strong_text in items_path:\n",
    "                            print(f\"{strong_text} 重复：{href}\")\n",
    "                        else:\n",
    "                            items_path[strong_text] = href\n",
    "                        \n",
    "\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"请求失败：{e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"解析失败：{e}\")\n",
    "        self.items_path = items_path\n",
    "        return items_path\n",
    "\n",
    "# ------------------- 调用示例 -------------------\n",
    "if __name__ == \"__main__\":\n",
    "    spider = SatisfactorySpider()\n",
    "    spider.get_all_formula()\n",
    "    with open('formula.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(spider.all_formula, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('formula.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    for key in data:\n",
    "        for formula in data[key][\"formula_list\"]:\n",
    "            inputs = formula[\"inputs\"]\n",
    "            formula[\"inputs\"] = {v[\"name\"]: {\"num\": v[\"num\"], \"speed\": v[\"speed\"], \"name\": v[\"name\"]} for v in inputs}\n",
    "            outputs = formula[\"outputs\"]\n",
    "            formula[\"outputs\"] = {v[\"name\"]: {\"num\": v[\"num\"], \"speed\": v[\"speed\"], \"name\": v[\"name\"]} for v in outputs}\n",
    "with open('formula.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
